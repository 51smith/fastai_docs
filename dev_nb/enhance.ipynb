{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai import *          # Quick access to most common functionality\n",
    "from fastai.vision import *   # Quick access to computer vision functionality\n",
    "from fastai.callbacks import *\n",
    "from torchvision.models import vgg16_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('/DATA/kaggle/imgnetloc/ILSVRC/Data/CLS-LOC/')\n",
    "PATH_TRN = PATH/'train'\n",
    "\n",
    "sz_lr=128\n",
    "scale,bs = 4,64\n",
    "sz_hr = sz_lr*scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(PATH_TRN.iterdir())\n",
    "fnames_full = []\n",
    "for class_folder in progress_bar(classes):\n",
    "    for fname in class_folder.iterdir():\n",
    "        fnames_full.append(fname)\n",
    "\n",
    "np.random.seed(42)\n",
    "keep_pct = 0.02\n",
    "keeps = np.random.rand(len(fnames_full)) < keep_pct\n",
    "image_fns = np.array(fnames_full, copy=False)[keeps]\n",
    "len(image_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pct = 0.1\n",
    "src = (ImageToImageList(image_fns)\n",
    "       .random_split_by_pct(valid_pct)\n",
    "       .label_from_func(lambda x: x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(bs, sz_lr, sz_hr):\n",
    "    tfms = get_transforms(do_flip=True, flip_vert=True,\n",
    "                          max_lighting=0.0, max_rotate=0.0,max_zoom=0.0,max_warp=0.0)\n",
    "    data = (src\n",
    "            .transform(tfms, size=sz_lr)\n",
    "            .transform_labels(size=sz_hr)\n",
    "            .databunch(bs=bs)\n",
    "            .normalize(imagenet_stats, do_y=True))\n",
    "    return data\n",
    "\n",
    "sz_lr = 72\n",
    "scale,bs = 4,24\n",
    "sz_hr = sz_lr*scale\n",
    "data = get_data(bs, sz_lr, sz_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data.dl().one_batch()\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(ni, nf, kernel_size=3, actn=True):\n",
    "    layers = [nn.Conv2d(ni, nf, kernel_size, padding=kernel_size//2)]\n",
    "    if actn: layers.append(nn.ReLU(True))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResSequential(nn.Module):\n",
    "    def __init__(self, layers, res_scale=1.0):\n",
    "        super().__init__()\n",
    "        self.res_scale = res_scale\n",
    "        self.m = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.m(x) * self.res_scale\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(nf):\n",
    "    return ResSequential(\n",
    "        [conv(nf, nf), conv(nf, nf, actn=False)],\n",
    "        0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(ni, nf, scale):\n",
    "    layers = []\n",
    "    for i in range(int(math.log(scale,2))):\n",
    "        layers += [conv(ni, nf*4), nn.PixelShuffle(2)]\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SrResnet(nn.Module):\n",
    "    def __init__(self, nf, scale):\n",
    "        super().__init__()\n",
    "        features = [conv(3, 64)]\n",
    "        for i in range(8): features.append(res_block(64))\n",
    "        features += [conv(64,64), upsample(64, 64, scale),\n",
    "                     nn.BatchNorm2d(64),\n",
    "                     conv(64, 3, actn=False)]\n",
    "        self.features = nn.Sequential(*features)\n",
    "        \n",
    "    def forward(self, x): return self.features(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SrResnet(64, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icnr(x, scale, init=nn.init.kaiming_normal_):\n",
    "    new_shape = [int(x.shape[0] / (scale ** 2))] + list(x.shape[1:])\n",
    "    subkernel = torch.zeros(new_shape)\n",
    "    subkernel = init(subkernel)\n",
    "    subkernel = subkernel.transpose(0, 1)\n",
    "    subkernel = subkernel.contiguous().view(subkernel.shape[0],\n",
    "                                            subkernel.shape[1], -1)\n",
    "    kernel = subkernel.repeat(1, 1, scale ** 2)\n",
    "    transposed_shape = [x.shape[1]] + [x.shape[0]] + list(x.shape[2:])\n",
    "    kernel = kernel.contiguous().view(transposed_shape)\n",
    "    kernel = kernel.transpose(0, 1)\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, nn.DataParallel(model,[0,1,2]), loss_func=F.mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(start_lr=1e-7, end_lr=1000)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "wd=1e-7\n",
    "learn.fit_one_cycle(1, lr, wd=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('pixel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('pixel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_lr = 128\n",
    "scale,bs = 4,16\n",
    "sz_hr = sz_lr*scale\n",
    "data = get_data(bs, sz_lr, sz_hr)\n",
    "learn = Learner(data, nn.DataParallel(model,[0,2]), loss_func=F.mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-7\n",
    "learn.fit_one_cycle(1, lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('pixel2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('pixel2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_x_y_pred(x, pred, y, figsize):\n",
    "    rows=x.shape[0]\n",
    "    fig, axs = plt.subplots(rows,3,figsize=figsize)\n",
    "    for i in range(rows):\n",
    "        show_image(x[i], ax=axs[i, 0])\n",
    "        show_image(pred[i], ax=axs[i, 1])\n",
    "        show_image(y[i], ax=axs[i, 2])\n",
    "    plt.tight_layout()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(learn.data.valid_dl))\n",
    "y_pred = model(x)\n",
    "x.shape, y.shape, y_pred.shape\n",
    "x_norm = learn.data.denorm(x.detach().cpu())\n",
    "y_norm = learn.data.denorm(y.detach().cpu())\n",
    "y_pred_norm = learn.data.denorm(y_pred.detach().cpu())\n",
    "plot_x_y_pred(x_norm[0:3], y_pred_norm[0:3], y_norm[0:3], figsize=y_pred_norm.shape[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_lr = 256\n",
    "scale,bs = 4,4\n",
    "sz_hr = sz_lr*scale\n",
    "data = get_data(bs, sz_lr, sz_hr)\n",
    "learn = Learner(data, nn.DataParallel(model,[0,1,2,3]), loss_func=F.mse_loss)\n",
    "\n",
    "lr = 2e-3\n",
    "wd=1e-7\n",
    "learn.fit_one_cycle(1, lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('pixel3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_vgg_feat = vgg16_bn(True).cuda().eval().features\n",
    "blocks = [i-1 for i,o in enumerate(children(m_vgg_feat))\n",
    "              if isinstance(o,nn.MaxPool2d)]\n",
    "blocks, [m_vgg_feat[i] for i in blocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureLoss(nn.Module):\n",
    "    def __init__(self, m_feat, layer_ids, layer_wgts):\n",
    "        super().__init__()\n",
    "        self.m_feat = m_feat\n",
    "        self.loss_features = [self.m_feat[i] for i in layer_ids]\n",
    "        self.hooks = hook_outputs(self.loss_features, detach=False)\n",
    "        self.wgts = layer_wgts\n",
    "        self.metrics = {}\n",
    "        self.metric_names = [f'feat_{i}' for i in range(len(layer_ids))]\n",
    "        for name in self.metric_names: self.metrics[name] = 0.\n",
    "\n",
    "    def make_feature(self, bs, o, clone=False):\n",
    "        feat = o.view(bs, -1)\n",
    "        if clone: feat = feat.clone()\n",
    "        return feat\n",
    "    \n",
    "    def make_features(self, x, clone=False):\n",
    "        bs = x.shape[0]\n",
    "        self.m_feat(x)\n",
    "        return [self.make_feature(bs, o, clone) for o in self.hooks.stored]\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        out_feat = self.make_features(target, clone=True)\n",
    "        in_feat = self.make_features(input)\n",
    "        self.feat_losses = [F.mse_loss(f_in, f_out)*w\n",
    "                            for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n",
    "        for i,name in enumerate(self.metric_names): self.metrics[name] = self.feat_losses[i]\n",
    "        self.loss = sum(self.feat_losses)\n",
    "        return self.loss\n",
    "        \n",
    "class ReportLossMetrics(LearnerCallback):\n",
    "    _order = -20 #Needs to run before the recorder\n",
    "        \n",
    "    def on_train_begin(self, **kwargs):\n",
    "        self.metric_names = self.learn.loss_func.metric_names\n",
    "        self.learn.recorder.add_metric_names(self.metric_names)\n",
    "    \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.metrics = {}\n",
    "        for name in self.metric_names:\n",
    "            self.metrics[name] = 0.\n",
    "        self.nums = 0\n",
    "    \n",
    "    def on_batch_end(self, last_target, train, **kwargs):\n",
    "        if not train:\n",
    "            bs = last_target.size(0)\n",
    "            for name in self.metric_names:\n",
    "                self.metrics[name] += bs * self.learn.loss_func.metrics[name]\n",
    "            self.nums += bs\n",
    "    \n",
    "    def on_epoch_end(self, **kwargs):\n",
    "        metrics = [self.metrics[name]/self.nums for name in self.metric_names]\n",
    "        self.learn.recorder.add_metrics(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = 64\n",
    "nres = 8\n",
    "model = SrResnet(, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_shuffle = model.features[nres+2][0][0]\n",
    "kernel = icnr(conv_shuffle.weight, scale=scale)\n",
    "conv_shuffle.weight.data.copy_(kernel);\n",
    "\n",
    "conv_shuffle = model.features[nres+2][2][0]\n",
    "kernel = icnr(conv_shuffle.weight, scale=scale)\n",
    "conv_shuffle.weight.data.copy_(kernel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_lr = 72\n",
    "scale,bs = 4,24\n",
    "sz_hr = sz_lr*scale\n",
    "\n",
    "data = get_data(bs, sz_lr, sz_hr)\n",
    "\n",
    "feat_loss = FeatureLoss(m_vgg_feat, blocks[:3], [0.25,0.50,0.25])\n",
    "learn = Learner(data, nn.DataParallel(model), loss_func=feat_loss, callback_fns=[ReportLossMetrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#learn.lr_find()\n",
    "#learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "learn.fit_one_cycle(1, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, lr/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('enhance_feat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('enhance_feat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(learn.data.valid_dl))\n",
    "y_pred = model(x)\n",
    "x.shape, y.shape, y_pred.shape\n",
    "x_norm = learn.data.denorm(x.detach().cpu())\n",
    "y_norm = learn.data.denorm(y.detach().cpu())\n",
    "y_pred_norm = learn.data.denorm(y_pred.detach().cpu())\n",
    "plot_x_y_pred(x_norm[0:3], y_pred_norm[0:3], y_norm[0:3], figsize=y_pred_norm.shape[-2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
