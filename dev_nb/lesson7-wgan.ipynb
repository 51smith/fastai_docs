{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "torch.cuda.set_device(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSun bedroom data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lesson, we'll be using the bedrooms from the [LSUN dataset](http://lsun.cs.princeton.edu/2017/). The full dataset is a bit too large so we'll use a sample from [kaggle](https://www.kaggle.com/jhoward/lsun_bedroom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data/bedroom')\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the next commands to download and extract the data in your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! kaggle datasets download -d jhoward/lsun_bedroom -p {path}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! unzip -q -n {path}/lsun_bedroom.zip -d {path}\n",
    "#! unzip -q -n {path}/sample.zip -d {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then grab all the images in the folder with the data block API. We don't create a validation set here for reasons we'll explain later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyItem(ItemBase):\n",
    "    def __init__(self, noise_sz): self.obj,self.data = noise_sz,torch.randn(noise_sz, 1, 1)\n",
    "    def __str__(self):  return ''\n",
    "    def apply_tfms(self, tfms, **kwargs): return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANItemList(ImageItemList):\n",
    "    _label_cls = ImageItemList\n",
    "    \n",
    "    def __init__(self, items, noise_sz:int=100, **kwargs):\n",
    "        super().__init__(items, **kwargs)\n",
    "        self.noise_sz = noise_sz\n",
    "        self.copy_new.append('noise_sz')\n",
    "    \n",
    "    def get(self, i): return NoisyItem(self.noise_sz)\n",
    "    def reconstruct(self, t): return NoisyItem(t.size(0))\n",
    "    \n",
    "    def show_xys(self, xs, ys, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n",
    "        super().show_xys(ys, xs, imgsize=imgsize, figsize=figsize, **kwargs)\n",
    "    \n",
    "    def show_xyzs(self, xs, ys, zs, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n",
    "        super().show_xys(zs, xs, imgsize=imgsize, figsize=figsize, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(bs, size):\n",
    "    train_ds = (GANItemList.from_folder(path).label_from_func(noop)\n",
    "               .transform(tfms=[crop_pad(size=size, row_pct=(0,1), col_pct=(0,1))], size=size, tfm_y=True))\n",
    "    return (ImageDataBunch.create(train_ds, valid_ds=None, path=path, bs=bs)\n",
    "                     .normalize(do_x=False, stats = [torch.tensor([0.5,0.5,0.5]), torch.tensor([0.5,0.5,0.5])], do_y=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin with a small side and use gradual resizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(128, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN stands for [Generative Adversarial Nets](https://arxiv.org/pdf/1406.2661.pdf) and were invented by Ian Goodfellow. The concept is that we will train two models at the same time: a generator and a critic. The generator will try to make new images similar to the ones in our dataset, and the critic job will try to classify real images from the ones the generator does. The generator returns images, the critic a single number (usually 0. for fake images and 1. for real ones).\n",
    "\n",
    "We train them against each other in the sense that at each step (more or less), we:\n",
    "1. Freeze the generator and train the critic for one step by:\n",
    "  - getting one batch of true images (let's call that `real`)\n",
    "  - generating one batch of fake images (let's call that `fake`)\n",
    "  - have the critic evaluate each batch and compute a loss function from that; the important part is that it rewards positively the detection of real images and penalizes the fake ones\n",
    "  - update the weights of the critic with the gradients of this loss\n",
    "  \n",
    "  \n",
    "2. Freeze the critic and train the generator for one step by:\n",
    "  - generating one batch of fake images\n",
    "  - evaluate the critic on it\n",
    "  - return a loss that rewards posisitivly the critic thinking those are real images; the important part is that it rewards positively the detection of real images and penalizes the fake ones\n",
    "  - update the weights of the generator with the gradients of this loss\n",
    "  \n",
    "Here, we'll use the [Wassertein GAN](https://arxiv.org/pdf/1701.07875.pdf).\n",
    "\n",
    "We create a generator and a critic that we pass to `gan_learner`. The noise_size is the size of the random vector from which our generator creates images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = models.basic_generator(in_size=64, n_channels=3, n_extra_layers=1)\n",
    "critic = models.basic_critic(in_size=64, n_channels=3, n_extra_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANModule(nn.Module):\n",
    "    \"Wrapper around a `generator` and a `critic` to create a GAN.\"\n",
    "    def __init__(self, generator:nn.Module, critic:nn.Module, gen_mode:bool=False):\n",
    "        super().__init__()\n",
    "        self.gen_mode = gen_mode\n",
    "        self.generator,self.critic = generator,critic\n",
    "    \n",
    "    def forward(self, *args):\n",
    "        return self.generator(*args) if self.gen_mode else self.critic(*args)\n",
    "    \n",
    "    def switch(self, gen_mode:bool=None):\n",
    "        \"Put the model in generator mode if `gen_mode`, in critic mode otherwise.\"\n",
    "        self.gen_mode = (not self.gen_mode) if gen_mode is None else gen_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(GANModule):\n",
    "    def __init__(self, loss_funcD:Callable, loss_funcG:Callable, gan_model:nn.Module):\n",
    "        super(GANModule, self).__init__()\n",
    "        self.loss_funcD,self.loss_funcG,self.gan_model = loss_funcD,loss_funcG,gan_model\n",
    "        \n",
    "    def generator(self, output, target):\n",
    "        fake = self.gan_model.critic(output)\n",
    "        return self.loss_funcG(fake, target)\n",
    "    \n",
    "    def critic(self, real, input):\n",
    "        fake = self.gan_model.generator(input.requires_grad_(False)).requires_grad_(True)\n",
    "        fake = self.gan_model.critic(fake)\n",
    "        return self.loss_funcD(real, fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANTrainer(LearnerCallback):\n",
    "    \"`LearnerCallback` that handles GAN Training.\"\n",
    "    _order=-20\n",
    "    def __init__(self, learn:Learner, clip:float=0.01, beta:float=0.98, gen_mode:bool=False):\n",
    "        super().__init__(learn)\n",
    "        self.clip,self.beta,self.gen_mode = clip,beta,gen_mode\n",
    "        self.generator,self.critic = self.model.generator,self.model.critic\n",
    "\n",
    "    def _set_trainable(self):\n",
    "        train_model = self.generator if     self.gen_mode else self.critic\n",
    "        loss_model  = self.generator if not self.gen_mode else self.critic\n",
    "        requires_grad(train_model, True)\n",
    "        requires_grad(loss_model, False)\n",
    "    \n",
    "    def on_train_begin(self, **kwargs):\n",
    "        \"Create the optimizers for the generator and disciminator.\"\n",
    "        self.opt_gen = self.opt.new([nn.Sequential(*flatten_model(self.generator))])\n",
    "        self.opt_disc = self.opt.new([nn.Sequential(*flatten_model(self.critic))])\n",
    "        self.switch(self.gen_mode)\n",
    "        self.dlosses,self.glosses = [],[]\n",
    "        self.smoothenerG,self.smoothenerD = SmoothenValue(self.beta),SmoothenValue(self.beta)\n",
    "        self.recorder.no_val=True\n",
    "        self.recorder.add_metric_names(['gen_loss', 'disc_loss'])\n",
    "        self.imgs,self.titles = [],[]\n",
    "    \n",
    "    def on_train_end(self, **kwargs):\n",
    "        self.switch(gen_mode=True)\n",
    "        \n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        \"Clamp the weights with `self.clip`.\"\n",
    "        if self.clip is not None:\n",
    "            for p in self.learn.model.critic.parameters(): \n",
    "                p.data.clamp_(-self.clip, self.clip)\n",
    "        return (last_input,last_target) if self.gen_mode else (last_target, last_input)\n",
    "        \n",
    "    def on_backward_begin(self, last_loss, last_output, **kwargs):\n",
    "        \"Record `last_loss` in the proper list.\"\n",
    "        last_loss = last_loss.detach().cpu()\n",
    "        smooth = self.smoothenerG if self.gen_mode else self.smoothenerD\n",
    "        losses = self.glosses if self.gen_mode else self.dlosses\n",
    "        smooth.add_value(last_loss)\n",
    "        losses.append(smooth.smooth)\n",
    "        if self.gen_mode:\n",
    "            self.last_gen = last_output.detach().cpu()\n",
    "    \n",
    "    def on_epoch_end(self, pbar, epoch, **kwargs):\n",
    "        \"Put the various losses in the recorder.\"\n",
    "        self.recorder.add_metrics([self.smoothenerG.smooth,self.smoothenerD.smooth])\n",
    "        self.imgs.append(Image(self.last_gen[0]/2 + 0.5))\n",
    "        self.titles.append(f'Epoch {epoch}')\n",
    "        pbar.show_imgs(self.imgs, self.titles)\n",
    "    \n",
    "    def switch(self, gen_mode:bool=None):\n",
    "        self.gen_mode = (not self.gen_mode) if gen_mode is None else gen_mode\n",
    "        self.opt.opt = self.opt_gen.opt if self.gen_mode else self.opt_disc.opt\n",
    "        self._set_trainable()\n",
    "        self.model.switch(gen_mode)\n",
    "        self.loss_func.switch(gen_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FixedGANSwitcher(LearnerCallback):\n",
    "    n_disc_iter:Union[int,Callable]\n",
    "    n_gen_iter:Union[int,Callable]\n",
    "    \n",
    "    def on_train_begin(self, **kwargs):\n",
    "        self.n_d,self.n_g = 0,0\n",
    "    \n",
    "    def on_batch_end(self, iteration, **kwargs):\n",
    "        if self.learn.gan_trainer.gen_mode: \n",
    "            self.n_g += 1\n",
    "            n_iter,n_in,n_out = self.n_gen_iter,self.n_d,self.n_g\n",
    "        else:\n",
    "            self.n_d += 1\n",
    "            n_iter,n_in,n_out = self.n_disc_iter,self.n_g,self.n_d\n",
    "        target = n_iter if isinstance(n_iter, int) else n_iter(n_in)\n",
    "        if target == n_out: \n",
    "            self.learn.gan_trainer.switch()\n",
    "            self.n_d,self.n_g = 0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = models.basic_generator(in_size=64, n_channels=3, n_extra_layers=1)\n",
    "critic = models.basic_critic(in_size=64, n_channels=3, n_extra_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GANModule(generator, critic)\n",
    "loss_func = GANLoss(WassersteinLoss(), NoopLoss(), gan)\n",
    "learn = Learner(data, gan, loss_func=loss_func, opt_func=optim.RMSprop, wd=0., \n",
    "                callback_fns=[GANTrainer, partial(FixedGANSwitcher, n_disc_iter=5,n_gen_iter=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(30,2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.gan_trainer.switch(gen_mode=True)\n",
    "learn.show_results(ds_type=DatasetType.Train, rows=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('wgan-30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, 2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(rows=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
