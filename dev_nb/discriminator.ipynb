{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "from torchvision.models import vgg16_bn\n",
    "\n",
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "path_hr = path/'images'\n",
    "path_lr = path/'crappy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crappify(fn,i):\n",
    "    dest = path_lr/fn.relative_to(path_hr)\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    img = PIL.Image.open(fn)\n",
    "    targ_sz = resize_to(img, 96, use_min=True)\n",
    "    img = img.resize(targ_sz, resample=PIL.Image.BILINEAR).convert('RGB')\n",
    "    img.save(dest, quality=random.randint(10,70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# il = ImageItemList.from_folder(path_hr)\n",
    "# parallel(crappify, il.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,size=32,128\n",
    "arch = models.resnet34\n",
    "src = ImageItemList.from_folder(path, include=['images', 'crappy']).random_split_by_pct(0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = src.label_from_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_crit = (ll.transform(get_transforms(max_zoom=2.), size=size)\n",
    "       .databunch(bs=bs).normalize(imagenet_stats))\n",
    "\n",
    "data_crit.c = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_crit.show_batch(rows=4, ds_type=DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(ni:int, nf:int, ks:int=3, stride:int=1, **kwargs):\n",
    "    return conv_layer(ni, nf, ks=ks, stride=stride, leaky=0.2, norm_type=NormType.Spectral, **kwargs)\n",
    "\n",
    "def critic(n_channels:int=3, nf:int=128, n_blocks:int=3, p:int=0.05):\n",
    "    layers = [\n",
    "        conv(n_channels, nf, ks=4, stride=2),\n",
    "        nn.Dropout2d(p/2),\n",
    "        conv(nf, nf)]\n",
    "    for i in range(n_blocks):\n",
    "        layers += [\n",
    "            nn.Dropout2d(p),\n",
    "            conv(nf, nf*2, ks=4, stride=2, self_attention=(i==0))]\n",
    "        nf *= 2\n",
    "    layers += [\n",
    "        conv(nf, 1, ks=4, bias=False, padding=0, use_activ=False),\n",
    "        nn.AdaptiveMaxPool2d(1),\n",
    "        Flatten(full=True)]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data_crit, critic(), metrics=accuracy_thresh, loss_func=BCEWithLogitsFlat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(8, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('critic-pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-train generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,size=32,128\n",
    "arch = models.resnet34\n",
    "src = ImageImageList.from_folder(path_lr).random_split_by_pct(0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(bs,size):\n",
    "    data = (src.label_from_func(lambda x: path_hr/x.name)\n",
    "           .transform(get_transforms(max_zoom=2.), size=size, tfm_y=True)\n",
    "           .databunch(bs=bs).normalize(imagenet_stats, do_y=True))\n",
    "\n",
    "    data.c = 3\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = get_data(bs,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-3\n",
    "learn = unet_learner(data_gen, arch, wd=wd, blur=True, norm_type=NormType.Weight, loss_func=MSELossFlat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(2, pct_start=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(2, slice(1e-6,1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(rows=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('gen-pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANModule(nn.Module):\n",
    "    \"Wrapper around a `generator` and a `critic` to create a GAN.\"\n",
    "    def __init__(self, generator:nn.Module, critic:nn.Module, gen_mode:bool=False):\n",
    "        super().__init__()\n",
    "        self.gen_mode = gen_mode\n",
    "        self.generator,self.critic = generator,critic\n",
    "    \n",
    "    def forward(self, *args):\n",
    "        return self.generator(*args) if self.gen_mode else self.critic(*args)\n",
    "    \n",
    "    def switch(self, gen_mode:bool=None):\n",
    "        \"Put the model in generator mode if `gen_mode`, in critic mode otherwise.\"\n",
    "        self.gen_mode = (not self.gen_mode) if gen_mode is None else gen_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(GANModule):\n",
    "    def __init__(self, loss_funcD:Callable, loss_funcG:Callable, gan_model:nn.Module):\n",
    "        super(GANModule, self).__init__()\n",
    "        self.loss_funcD,self.loss_funcG,self.gan_model = loss_funcD,loss_funcG,gan_model\n",
    "        \n",
    "    def generator(self, output, target):\n",
    "        fake = self.gan_model.critic(output)\n",
    "        return self.loss_funcG(fake, target)\n",
    "    \n",
    "    def critic(self, real, input):\n",
    "        fake = self.gan_model.generator(input.requires_grad_(False)).requires_grad_(True)\n",
    "        fake = self.gan_model.critic(fake)\n",
    "        return self.loss_funcD(real, fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANTrainer(LearnerCallback):\n",
    "    \"`LearnerCallback` that handles GAN Training.\"\n",
    "    _order=-20\n",
    "    def __init__(self, learn:Learner, switch_eval:bool=False, clip:float=0.01, beta:float=0.98, gen_mode:bool=False):\n",
    "        super().__init__(learn)\n",
    "        self.switch_eval,self.clip,self.beta,self.gen_mode = switch_eval,clip,beta,gen_mode\n",
    "        self.generator,self.critic = self.model.generator,self.model.critic\n",
    "\n",
    "    def _set_trainable(self):\n",
    "        train_model = self.generator if     self.gen_mode else self.critic\n",
    "        loss_model  = self.generator if not self.gen_mode else self.critic\n",
    "        requires_grad(train_model, True)\n",
    "        requires_grad(loss_model, False)\n",
    "        if self.switch_eval:\n",
    "            train_model.train()\n",
    "            loss_model.eval()\n",
    "    \n",
    "    def on_train_begin(self, **kwargs):\n",
    "        \"Create the optimizers for the generator and disciminator.\"\n",
    "        self.opt_gen = self.opt.new([nn.Sequential(*flatten_model(self.generator))])\n",
    "        self.opt_disc = self.opt.new([nn.Sequential(*flatten_model(self.critic))])\n",
    "        self.switch(self.gen_mode)\n",
    "        self.dlosses,self.glosses = [],[]\n",
    "        self.smoothenerG,self.smoothenerD = SmoothenValue(self.beta),SmoothenValue(self.beta)\n",
    "        self.recorder.no_val=True\n",
    "        self.recorder.add_metric_names(['gen_loss', 'disc_loss'])\n",
    "        self.imgs,self.titles = [],[]\n",
    "    \n",
    "    def on_train_end(self, **kwargs):\n",
    "        self.switch(gen_mode=True)\n",
    "        \n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        \"Clamp the weights with `self.clip`.\"\n",
    "        if self.clip is not None:\n",
    "            for p in self.learn.model.critic.parameters(): \n",
    "                p.data.clamp_(-self.clip, self.clip)\n",
    "        return (last_input,last_target) if self.gen_mode else (last_target, last_input)\n",
    "        \n",
    "    def on_backward_begin(self, last_loss, last_output, **kwargs):\n",
    "        \"Record `last_loss` in the proper list.\"\n",
    "        last_loss = last_loss.detach().cpu()\n",
    "        if self.gen_mode:\n",
    "            self.smoothenerG.add_value(last_loss)\n",
    "            self.glosses.append(self.smoothenerG.smooth)\n",
    "            self.last_gen = last_output.detach().cpu()\n",
    "        else:\n",
    "            self.smoothenerD.add_value(last_loss)\n",
    "            self.dlosses.append(self.smoothenerD.smooth)\n",
    "    \n",
    "    def on_epoch_end(self, pbar, epoch, **kwargs):\n",
    "        \"Put the various losses in the recorder.\"\n",
    "        self.recorder.add_metrics([self.smoothenerG.smooth,self.smoothenerD.smooth])\n",
    "        self.imgs.append(Image(self.last_gen[0]/2 + 0.5))\n",
    "        self.titles.append(f'Epoch {epoch}')\n",
    "        pbar.show_imgs(self.imgs, self.titles)\n",
    "    \n",
    "    def switch(self, gen_mode:bool=None):\n",
    "        self.gen_mode = (not self.gen_mode) if gen_mode is None else gen_mode\n",
    "        self.opt.opt = self.opt_gen.opt if self.gen_mode else self.opt_disc.opt\n",
    "        self._set_trainable()\n",
    "        self.model.switch(gen_mode)\n",
    "        self.loss_func.switch(gen_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FixedGANSwitcher(LearnerCallback):\n",
    "    n_disc_iter:Union[int,Callable]\n",
    "    n_gen_iter:Union[int,Callable]\n",
    "    \n",
    "    def on_train_begin(self, **kwargs):\n",
    "        self.n_d,self.n_g = 0,0\n",
    "    \n",
    "    def on_batch_end(self, iteration, **kwargs):\n",
    "        if self.learn.gan_trainer.gen_mode: \n",
    "            self.n_g += 1\n",
    "            n_iter,n_in,n_out = self.n_gen_iter,self.n_d,self.n_g\n",
    "        else:\n",
    "            self.n_d += 1\n",
    "            n_iter,n_in,n_out = self.n_disc_iter,self.n_g,self.n_d\n",
    "        target = n_iter if isinstance(n_iter, int) else n_iter(n_in)\n",
    "        if target == n_out: \n",
    "            self.learn.gan_trainer.switch()\n",
    "            self.n_d,self.n_g = 0,0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train generator with critic loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_crit = Learner(data_crit, critic().eval(), loss_func=BCEWithLogitsFlat()).load('critic-pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_crit.model = learn_crit.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CriticLoss(nn.Module):\n",
    "    def __init__(self, critic, mult=1.):\n",
    "        super().__init__()\n",
    "        self.critic = critic\n",
    "        requires_grad(self.critic.model, False)\n",
    "        self.metric_names = ['pixel','critic']\n",
    "        self.mult = mult\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        pred = self.critic.model(input)\n",
    "        critic_targ = pred.new_ones(pred.shape[0])\n",
    "        critic_loss = self.critic.loss_func(pred, critic_targ)*self.mult\n",
    "        px_loss = F.mse_loss(input,target)\n",
    "        self.metrics = dict(zip(self.metric_names, [px_loss, critic_loss]))\n",
    "        return px_loss + critic_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = CriticLoss(learn_crit, mult=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-3\n",
    "learn = unet_learner(data_gen, arch, wd=wd, blur=True, norm_type=NormType.Weight,\n",
    "                     loss_func=loss_func, callback_fns=LossMetrics).load('gen-pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data_gen.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.cuda().detach()\n",
    "y = y.cuda().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func(y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot(skip_end=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, pct_start=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func.mult = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, slice(1e-3), pct_start=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(rows=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
