{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "from torchvision.models import vgg16_bn\n",
    "\n",
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "path_hr = path/'images'\n",
    "path_lr = path/'crappy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crappify(fn,i):\n",
    "    dest = path_lr/fn.relative_to(path_hr)\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    img = PIL.Image.open(fn)\n",
    "    targ_sz = resize_to(img, 96, use_min=True)\n",
    "    img = img.resize(targ_sz, resample=PIL.Image.BILINEAR).convert('RGB')\n",
    "    img.save(dest, quality=random.randint(10,70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# il = ImageItemList.from_folder(path_hr)\n",
    "# parallel(crappify, il.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,size=32,128\n",
    "arch = models.resnet34\n",
    "classes = ['crappy', 'images']\n",
    "src = ImageItemList.from_folder(path, include=classes).random_split_by_pct(0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = src.label_from_folder(classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_crit = (ll.transform(get_transforms(max_zoom=2.), size=size)\n",
    "       .databunch(bs=bs).normalize(imagenet_stats))\n",
    "\n",
    "data_crit.c = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_crit.show_batch(rows=4, ds_type=DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(ni:int, nf:int, ks:int=3, stride:int=1, **kwargs):\n",
    "    return conv_layer(ni, nf, ks=ks, stride=stride, leaky=0.2, norm_type=NormType.Spectral, **kwargs)\n",
    "\n",
    "def critic(n_channels:int=3, nf:int=128, n_blocks:int=3, p:int=0.05):\n",
    "    layers = [\n",
    "        conv(n_channels, nf, ks=4, stride=2),\n",
    "        nn.Dropout2d(p/2),\n",
    "        conv(nf, nf)]\n",
    "    for i in range(n_blocks):\n",
    "        layers += [\n",
    "            nn.Dropout2d(p),\n",
    "            conv(nf, nf*2, ks=4, stride=2, self_attention=(i==0))]\n",
    "        nf *= 2\n",
    "    layers += [\n",
    "        conv(nf, 1, ks=4, bias=False, padding=0, use_activ=False),\n",
    "        nn.AdaptiveMaxPool2d(1),\n",
    "        Flatten(full=True)]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_critic = Learner(data_crit, critic(), metrics=accuracy_thresh, loss_func=BCEWithLogitsFlat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_critic.fit_one_cycle(8, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_critic.save('critic-pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-train generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,size=32,128\n",
    "arch = models.resnet34\n",
    "src = ImageImageList.from_folder(path_lr).random_split_by_pct(0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(bs,size):\n",
    "    data = (src.label_from_func(lambda x: path_hr/x.name)\n",
    "           .transform(get_transforms(max_zoom=2.), size=size, tfm_y=True)\n",
    "           .databunch(bs=bs).normalize(imagenet_stats, do_y=True))\n",
    "\n",
    "    data.c = 3\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = get_data(bs,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen = unet_learner(data_gen, arch, wd=wd, blur=True, norm_type=NormType.Spectral, self_attention=True, loss_func=MSELossFlat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen.fit_one_cycle(2, pct_start=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen.fit_one_cycle(2, slice(1e-6,1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen.show_results(rows=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen.save('gen-pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANModule(nn.Module):\n",
    "    \"Wrapper around a `generator` and a `critic` to create a GAN.\"\n",
    "    def __init__(self, generator:nn.Module=None, critic:nn.Module=None, gen_mode:bool=False):\n",
    "        super().__init__()\n",
    "        self.gen_mode = gen_mode\n",
    "        if generator: self.generator,self.critic = generator,critic\n",
    "    \n",
    "    def forward(self, *args):\n",
    "        return self.generator(*args) if self.gen_mode else self.critic(*args)\n",
    "\n",
    "    def switch(self, gen_mode:bool=None):\n",
    "        \"Put the model in generator mode if `gen_mode`, in critic mode otherwise.\"\n",
    "        self.gen_mode = (not self.gen_mode) if gen_mode is None else gen_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generate real/fake in DL and use std BCE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(GANModule):\n",
    "    def __init__(self, loss_funcC:Callable, loss_funcG:Callable, gan_model:GANModule):\n",
    "        super().__init__()\n",
    "        self.loss_funcC,self.loss_funcG,self.gan_model = loss_funcC,loss_funcG,gan_model\n",
    "        \n",
    "    def generator(self, output, target):\n",
    "        # we're training the generator, by getting the critic to output large (real) predictions\n",
    "        # `output` is fake output from `gan_model.generator`\n",
    "        fake_pred = self.gan_model.critic(output)\n",
    "        # in a basic GAN this will just take the mean of fake_pred\n",
    "        return self.loss_funcG(fake_pred, target, output)\n",
    "    \n",
    "    def critic(self, real_pred, input):\n",
    "        # we're training the critic, by getting it to recognize which images are real vs fake\n",
    "        # `real_pred` is a batch of predictions on real images\n",
    "        # `input` is a batch of inputs to the generator, which we need to generate from first\n",
    "        fake = self.gan_model.generator(input.requires_grad_(False)).requires_grad_(True)\n",
    "        # now we can see whether the critic thinks these are real; we're trying to get it to realize they're not\n",
    "        fake_pred = self.gan_model.critic(fake)\n",
    "        # this will generally just take mean of the difference\n",
    "        return self.loss_funcC(real_pred, fake_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANTrainer(LearnerCallback):\n",
    "    \"Handles GAN Training.\"\n",
    "    _order=-20\n",
    "    def __init__(self, learn:Learner, switch_eval:bool=False, clip:float=None, beta:float=0.98, gen_first:bool=False):\n",
    "        super().__init__(learn)\n",
    "        self.switch_eval,self.clip,self.beta,self.gen_first = switch_eval,clip,beta,gen_first\n",
    "        self.generator,self.critic = self.model.generator,self.model.critic\n",
    "\n",
    "    def _set_trainable(self):\n",
    "        train_model = self.generator if     self.gen_mode else self.critic\n",
    "        loss_model  = self.generator if not self.gen_mode else self.critic\n",
    "        requires_grad(train_model, True)\n",
    "        requires_grad(loss_model, False)\n",
    "        if self.switch_eval:\n",
    "            train_model.train()\n",
    "            loss_model.eval()\n",
    "    \n",
    "    def on_train_begin(self, **kwargs):\n",
    "        \"Create the optimizers for the generator and disciminator.\"\n",
    "        if not getattr(self,'opt_gen',None):\n",
    "            self.opt_gen = self.opt.new([nn.Sequential(*flatten_model(self.generator))])\n",
    "        else: self.opt_gen.lr,self.opt_gen.wd = self.opt.lr,self.opt.wd\n",
    "        if not getattr(self,'opt_critic',None):\n",
    "            self.opt_critic = self.opt.new([nn.Sequential(*flatten_model(self.critic))])\n",
    "        else: self.opt_critic.lr,self.opt_critic.wd = self.opt.lr,self.opt.wd\n",
    "        self.gen_mode = self.gen_first\n",
    "        self.switch(self.gen_mode)\n",
    "        self.closses,self.glosses = [],[]\n",
    "        self.smoothenerG,self.smoothenerC = SmoothenValue(self.beta),SmoothenValue(self.beta)\n",
    "        self.recorder.no_val=True\n",
    "        self.recorder.add_metric_names(['gen_loss', 'disc_loss'])\n",
    "        self.imgs,self.titles = [],[]\n",
    "    \n",
    "    def on_train_end(self, **kwargs): self.switch(gen_mode=True)\n",
    "        \n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        \"Clamp the weights with `self.clip`.\"\n",
    "        if self.clip is not None:\n",
    "            for p in self.critic.parameters(): p.data.clamp_(-self.clip, self.clip)\n",
    "        return (last_input,last_target) if self.gen_mode else (last_target, last_input)\n",
    "        \n",
    "    def on_backward_begin(self, last_loss, last_output, **kwargs):\n",
    "        \"Record `last_loss` in the proper list.\"\n",
    "        last_loss = last_loss.detach().cpu()\n",
    "        if self.gen_mode:\n",
    "            self.smoothenerG.add_value(last_loss)\n",
    "            self.glosses.append(self.smoothenerG.smooth)\n",
    "            self.last_gen = last_output.detach().cpu()\n",
    "        else:\n",
    "            self.smoothenerC.add_value(last_loss)\n",
    "            self.closses.append(self.smoothenerC.smooth)\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, **kwargs):\n",
    "        self.switch(self.gen_mode)\n",
    "\n",
    "    def on_epoch_end(self, pbar, epoch, **kwargs):\n",
    "        \"Put the various losses in the recorder.\"\n",
    "        self.recorder.add_metrics([getattr(self.smoothenerG,'smooth',None),getattr(self.smoothenerC,'smooth',None)])\n",
    "#         self.imgs.append(Image(self.last_gen[0]/2 + 0.5))\n",
    "#         self.titles.append(f'Epoch {epoch}')\n",
    "#         pbar.show_imgs(self.imgs, self.titles)\n",
    "    \n",
    "    def switch(self, gen_mode:bool=None):\n",
    "        self.gen_mode = (not self.gen_mode) if gen_mode is None else gen_mode\n",
    "        self.opt.opt = self.opt_gen.opt if self.gen_mode else self.opt_critic.opt\n",
    "        self._set_trainable()\n",
    "        self.model.switch(gen_mode)\n",
    "        self.loss_func.switch(gen_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FixedGANSwitcher(LearnerCallback):\n",
    "    n_disc_iter:Union[int,Callable]\n",
    "    n_gen_iter:Union[int,Callable]\n",
    "    \n",
    "    def on_train_begin(self, **kwargs):\n",
    "        self.n_d,self.n_g = 0,0\n",
    "    \n",
    "    def on_batch_end(self, iteration, **kwargs):\n",
    "        if self.learn.gan_trainer.gen_mode: \n",
    "            self.n_g += 1\n",
    "            n_iter,n_in,n_out = self.n_gen_iter,self.n_d,self.n_g\n",
    "        else:\n",
    "            self.n_d += 1\n",
    "            n_iter,n_in,n_out = self.n_disc_iter,self.n_g,self.n_d\n",
    "        target = n_iter if isinstance(n_iter, int) else n_iter(n_in)\n",
    "        if target == n_out: \n",
    "            self.learn.gan_trainer.switch()\n",
    "            self.n_d,self.n_g = 0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveGANStopper(LearnerCallback):\n",
    "    gen_thresh = 1.\n",
    "    critic_thresh = 0.1\n",
    "    \n",
    "    def on_train_begin(self, **kwargs): self.stop=False\n",
    "    \n",
    "    def on_batch_end(self, iteration, last_target, **kwargs):\n",
    "        if self.gan_trainer.gen_mode: \n",
    "#             real_pred = self.gan_trainer.critic(last_target)\n",
    "#             ones = real_pred.new_ones(real_pred.shape[0])\n",
    "#             loss_chk = loss_critic(real_pred, ones)\n",
    "#             print(loss_chk)\n",
    "#             if loss_chk > 0.5: self.stop=True\n",
    "            loss = self.gan_trainer.smoothenerG.smooth\n",
    "            if loss < self.gen_thresh: self.stop=True\n",
    "        else:\n",
    "            loss = self.gan_trainer.smoothenerC.smooth\n",
    "            if loss < self.critic_thresh: self.stop=True\n",
    "        print(self.gan_trainer.gen_mode, loss, self.stop)\n",
    "        return self.stop\n",
    "    \n",
    "    def on_epoch_end(self, iteration, **kwargs):\n",
    "        return self.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_critic = BCEWithLogitsFlat()\n",
    "loss_gen    = MSELossFlat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_C(real_pred, fake_pred):\n",
    "    ones  = real_pred.new_ones (real_pred.shape[0])\n",
    "    zeros = fake_pred.new_zeros(fake_pred.shape[0])\n",
    "    return (loss_critic(real_pred, ones) + loss_critic(fake_pred, zeros)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_G(fake_pred, output, target):\n",
    "    ones = fake_pred.new_ones(fake_pred.shape[0])\n",
    "    gan_loss = loss_critic(fake_pred, ones)\n",
    "    px_loss  = loss_gen(output, target)\n",
    "    return gan_loss + px_loss * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train generator with critic loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_crit = Learner(data_crit, critic(), loss_func=loss_critic).load('critic-pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen = unet_learner(data_gen, arch, wd=wd, blur=True, norm_type=NormType.Spectral,\n",
    "                         self_attention=True, loss_func=loss_gen).load('gen-pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GANModule(learn_gen.model, learn_crit.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = GANLoss(loss_C, loss_G, gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data_gen, gan, loss_func=loss_func, callback_fns=[AdaptiveGANStopper], opt_func=optim.RMSprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GANTrainer(learn, switch_eval=True)\n",
    "learn.gan_trainer = trainer\n",
    "learn.callbacks.append(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = learn_crit.model\n",
    "mg = learn_gen.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.create_opt(lr=defaults.lr)\n",
    "learn.recorder = Recorder(learn)\n",
    "trainer.on_train_begin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.eval();\n",
    "mg.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = learn.data.one_batch(denorm=False, detach=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.switch(gen_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = learn.model(y.clone())\n",
    "learn.loss_func(z,x.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_pred = learn_crit.model(y.clone())\n",
    "fake = learn_gen.model(x.clone().requires_grad_(False)).requires_grad_(True)\n",
    "fake_pred = learn_crit.model(fake.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = real_pred.new_ones(real_pred.shape[0])\n",
    "zeros = fake_pred.new_zeros(fake_pred.shape[0])\n",
    "loss_r = loss_critic(real_pred, ones)\n",
    "loss_f = loss_critic(fake_pred, zeros) \n",
    "loss_c = (loss_r + loss_f) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_r,loss_f,loss_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.switch(gen_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.eval();\n",
    "mg.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = learn.model(x)\n",
    "learn.loss_func(z,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stuff done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.gen_first=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.gen_first=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.switch(gen_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data_gen.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.cuda().detach()\n",
    "y = y.cuda().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func(y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot(skip_end=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, pct_start=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func.mult = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, slice(1e-3), pct_start=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(rows=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CriticLoss(nn.Module):\n",
    "    def __init__(self, critic, mult=1.):\n",
    "        super().__init__()\n",
    "        self.critic = critic\n",
    "        requires_grad(self.critic.model, False)\n",
    "        self.metric_names = ['pixel','critic']\n",
    "        self.mult = mult\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        pred = self.critic.model(input)\n",
    "        critic_targ = pred.new_ones(pred.shape[0])\n",
    "        critic_loss = self.critic.loss_func(pred, critic_targ)*self.mult\n",
    "        px_loss = F.mse_loss(input,target)\n",
    "        self.metrics = dict(zip(self.metric_names, [px_loss, critic_loss]))\n",
    "        return px_loss + critic_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = CriticLoss(learn_crit, mult=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
