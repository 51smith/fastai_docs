{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSun data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('../data/lsun')\n",
    "IMG_PATH = PATH/'bedroom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv_file(sample=False):\n",
    "    files = PATH.glob('bedroom/**/*.jpg')\n",
    "    with (PATH/'files.csv').open('w') as fo:\n",
    "        for f in files: \n",
    "            if not sample or random.random() < 0.1: fo.write(f'{f},0\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_csv_file(sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH/'files.csv', header=None)\n",
    "fns, ys = np.array(df[0]), np.array(df[1])\n",
    "train_ds = ImageDataset(fns, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 64\n",
    "train_tds = DatasetTfm(train_ds, tfms = [crop_pad(size=size, row_pct=(0,1), col_pct=(0,1))], size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch.create(train_tds, valid_ds=None, bs=128)\n",
    "data.valid_dl = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn_lr(ni:int, nf:int, ks:int=3, stride:int=1, slope=0.1, bn:bool=True)->nn.Sequential:\n",
    "    \"Create Conv2d->BatchNorm2d->LeakyReLu layer with `slope`: `ni` input, `nf` out filters, `ks` kernel, `stride`:stride.\"\n",
    "    layers = [conv2d(ni, nf, ks, stride)]\n",
    "    if bn: layers.append(nn.BatchNorm2d(nf))\n",
    "    layers.append(nn.LeakyReLU(negative_slope=slope, inplace=True))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convT_bn_relu(ni:int, nf:int, ks:int=2, stride:int=2, padding:int=0, slope=0.1, bn:bool=True)->nn.Sequential:\n",
    "    \"Create Conv2dT->BatchNorm2d->LeakyReLu layer with `slope`: `ni` input, `nf` out filters, `ks` kernel, `stride`:stride.\"\n",
    "    layers = [conv2d_trans(ni, nf, ks, stride, padding)]\n",
    "    if bn: layers.append(nn.BatchNorm2d(nf))\n",
    "    layers.append(nn.LeakyReLU(negative_slope=slope, inplace=True))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AvgFlatten():\n",
    "    return Lambda(lambda x: x.mean().view(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(in_size, n_channels, n_features, n_extra_layers=0):\n",
    "    layers = [conv_bn_lr(n_channels, n_features, 4, 2, bn=False)]\n",
    "    cur_size, cur_ftrs = in_size//2, n_features\n",
    "    layers.append(nn.Sequential(*[conv_bn_lr(cur_ftrs, cur_ftrs, 3, 1) for _ in range(n_extra_layers)]))\n",
    "    while cur_size > 4:\n",
    "        layers.append(conv_bn_lr(cur_ftrs, cur_ftrs*2, 4, 2))\n",
    "        cur_ftrs *= 2 ; cur_size //= 2\n",
    "    layers += [conv2d(cur_ftrs, 1, 4, padding=0), AvgFlatten()]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(in_size, noise_sz, n_channels, n_features, n_extra_layers=0):\n",
    "    cur_size, cur_ftrs = 4, n_features//2\n",
    "    while cur_size < in_size:  cur_size *= 2; cur_ftrs *= 2\n",
    "    layers = [convT_bn_relu(noise_sz, cur_ftrs, 4, 1)]\n",
    "    cur_size = 4\n",
    "    while cur_size < in_size // 2:\n",
    "        layers.append(convT_bn_relu(cur_ftrs, cur_ftrs//2, 4, 2, 1))\n",
    "        cur_ftrs //= 2; cur_size *= 2\n",
    "    layers += [convT_bn_relu(cur_ftrs, cur_ftrs, 3, 1, 1) for _ in range(n_extra_layers)]\n",
    "    layers.append(conv2d_trans(cur_ftrs, n_channels, 4, 2, 1))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator(64, 100, 3, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator(64, 3, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_size, noise_sz, n_channels, n_features, n_extra_layers=0):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator(in_size, n_channels, n_features, n_extra_layers)\n",
    "        self.generator = generator(in_size, noise_sz, n_channels, n_features, n_extra_layers)\n",
    "    \n",
    "    def forward(self, x, gen=False):\n",
    "        return self.generator(x) if gen else self.discriminator(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_disc_iter(gen_iter):\n",
    "    return 100 if (gen_iter < 25 or gen_iter%500 == 0) else 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_sz = 100\n",
    "def create_noise(x, b): return x.new(b, noise_sz, 1, 1).normal_(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GANTrainer(LearnerCallback):\n",
    "    n_disc_iter:Callable = standard_disc_iter\n",
    "    clip:float = -0.01\n",
    "    bs:int = 64\n",
    "    \n",
    "    def _set_trainable(self, gen=False):\n",
    "        requires_grad(self.learn.model.generator, gen)\n",
    "        requires_grad(self.learn.model.discriminator, not gen)\n",
    "        if gen:\n",
    "            self.opt_gen.lr, self.opt_gen.mom = self.learn.opt.lr, self.learn.opt.mom\n",
    "            self.opt_gen.wd, self.opt_gen.beta = self.learn.opt.wd, self.learn.opt.beta\n",
    "    \n",
    "    def on_train_begin(self, **kwargs):\n",
    "        opt_fn = self.learn.opt_fn\n",
    "        lr, wd, true_wd, bn_wd = self.learn.opt.lr, self.learn.opt.wd, self.learn.opt.true_wd, self.learn.opt.bn_wd\n",
    "        self.opt_gen = OptimWrapper.create(opt_fn, lr, \n",
    "                                      [nn.Sequential(*flatten_model(self.learn.model.generator))], \n",
    "                                      wd=wd, true_wd=true_wd, bn_wd=bn_wd)\n",
    "        self.opt_disc = OptimWrapper.create(opt_fn, lr, \n",
    "                                      [nn.Sequential(*flatten_model(self.learn.model.discriminator))],\n",
    "                                      wd=wd, true_wd=true_wd, bn_wd=bn_wd)\n",
    "        self.learn.opt.opt = self.opt_disc.opt\n",
    "        self.disc_iters, self.gen_iters = 0, 0\n",
    "        self._set_trainable()\n",
    "    \n",
    "    def on_batch_begin(self, **kwargs):\n",
    "        for p in self.learn.model.discriminator.parameters(): p.data.clamp_(-self.clip, self.clip)\n",
    "        \n",
    "    def on_backward_begin(self, last_loss, last_input, **kwargs):\n",
    "        fake = self.learn.model(create_noise(last_input, last_input.size(0)), gen=True)\n",
    "        return last_loss - self.learn.model(fake)\n",
    "    \n",
    "    def on_batch_end(self, last_input, **kwargs):\n",
    "        self.disc_iters += 1\n",
    "        if self.disc_iters == self.n_disc_iter(self.gen_iters):\n",
    "            self.disc_iters = 0\n",
    "            self._set_trainable(True)\n",
    "            loss = self.learn.model(self.learn.model(create_noise(last_input,self.bs), gen=True)).mean(0).view(1)\n",
    "            loss.backward()\n",
    "            self.opt_gen.step()\n",
    "            self.opt_gen.zero_grad()\n",
    "            self.gen_iters += 1\n",
    "            self._set_trainable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoopLoss(nn.Module):\n",
    "    \n",
    "    def forward(self, output, target): return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan = WGAN(64, 100, 3, 64, 1)\n",
    "learner = Learner(data, wgan, loss_fn=NoopLoss(), opt_fn=optim.RMSprop, wd=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = GANTrainer(learner, bs=128)\n",
    "learner.callbacks.append(cb)\n",
    "learner.fit(2, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(learner.data.train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = learner.model(create_noise(x,64), gen=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tst[0].cpu().numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
