{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module contains many layer classes that we might be interested in using in our models. These layers complement the default [Pytorch layers](https://pytorch.org/docs/stable/nn.html) which we can also use as predefined layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.docs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## <a id=AdaptiveConcatPool2d></a>`class` `AdaptiveConcatPool2d`\n",
       "> `AdaptiveConcatPool2d`(`sz`:`Optional`\\[`int`\\]=`None`) :: [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n",
       "\n",
       "\n",
       "Layer that concats `AdaptiveAvgPool2d` and `AdaptiveMaxPool2d` <a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L60\">[source]</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(AdaptiveConcatPool2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from fastai.gen_doc.nbdoc import *\n",
    "from fastai.layers import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`AdaptiveConcatPool2d`](/layers.html#AdaptiveConcatPool2d) object uses adaptive average pooling and adaptive max pooling and concatenates them both. We use this because it provides the model with the information of both methods and improves performance. This technique is called `adaptive` because it allows us to decide on what output dimensions we want, instead of choosing the input's dimensions to fit a desired output size.\n",
    "\n",
    "Let's try training with Adaptive Average Pooling first, then with Adaptive Max Pooling and finally with the concatenation of them both to see how they fare in performance.\n",
    "\n",
    "We will first define a [`simple_cnn`](/layers.html#simple_cnn) using [Adapative Max Pooling](https://pytorch.org/docs/stable/nn.html#torch.nn.AdaptiveMaxPool2d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cnn(actns:Collection[int], kernel_szs:Collection[int]=None,\n",
    "               strides:Collection[int]=None) -> nn.Sequential:\n",
    "    \"CNN with `conv2d_relu` layers defined by `actns`, `kernel_szs` and `strides`\"\n",
    "    nl = len(actns)-1\n",
    "    kernel_szs = ifnone(kernel_szs, [3]*nl)\n",
    "    strides    = ifnone(strides   , [2]*nl)\n",
    "    layers = [conv2d_relu(actns[i], actns[i+1], kernel_szs[i], stride=strides[i])\n",
    "        for i in range(len(strides))]\n",
    "    layers.append(nn.Sequential(nn.AdaptiveMaxPool2d(1), Flatten()))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=5), HTML(value=''))), HTML(value='epoch  train loss  va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 00:27\n",
      "epoch  train loss  valid loss  accuracy\n",
      "0      0.103762    0.091423    0.968106  (00:05)\n",
      "1      0.063399    0.072915    0.974975  (00:05)\n",
      "2      0.046143    0.046770    0.983317  (00:05)\n",
      "3      0.033929    0.036166    0.984298  (00:05)\n",
      "4      0.027374    0.029849    0.989205  (00:05)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = simple_cnn((3,16,16,2))\n",
    "learner = Learner(data, model, metrics=[accuracy])\n",
    "learner.fit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try with [Adapative Average Pooling](https://pytorch.org/docs/stable/nn.html#torch.nn.AdaptiveAvgPool2d) now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cnn(actns:Collection[int], kernel_szs:Collection[int]=None,\n",
    "               strides:Collection[int]=None) -> nn.Sequential:\n",
    "    \"CNN with `conv2d_relu` layers defined by `actns`, `kernel_szs` and `strides`\"\n",
    "    nl = len(actns)-1\n",
    "    kernel_szs = ifnone(kernel_szs, [3]*nl)\n",
    "    strides    = ifnone(strides   , [2]*nl)\n",
    "    layers = [conv2d_relu(actns[i], actns[i+1], kernel_szs[i], stride=strides[i])\n",
    "        for i in range(len(strides))]\n",
    "    layers.append(nn.Sequential(nn.AdaptiveAvgPool2d(1), Flatten()))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=5), HTML(value=''))), HTML(value='epoch  train loss  va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 00:27\n",
      "epoch  train loss  valid loss  accuracy\n",
      "0      0.137460    0.110767    0.962218  (00:05)\n",
      "1      0.105729    0.080629    0.972522  (00:05)\n",
      "2      0.081463    0.060069    0.979392  (00:05)\n",
      "3      0.062050    0.055416    0.981354  (00:05)\n",
      "4      0.050456    0.035258    0.988224  (00:05)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = simple_cnn((3,16,16,2))\n",
    "learner = Learner(data, model, metrics=[accuracy])\n",
    "learner.fit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we will try with the concatenation of them both [`AdaptiveConcatPool2d`](/layers.html#AdaptiveConcatPool2d). We will see that, in fact, it increases our accuracy and decreases our loss considerably!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cnn(actns:Collection[int], kernel_szs:Collection[int]=None,\n",
    "               strides:Collection[int]=None) -> nn.Sequential:\n",
    "    \"CNN with `conv2d_relu` layers defined by `actns`, `kernel_szs` and `strides`\"\n",
    "    nl = len(actns)-1\n",
    "    kernel_szs = ifnone(kernel_szs, [3]*nl)\n",
    "    strides    = ifnone(strides   , [2]*nl)\n",
    "    layers = [conv2d_relu(actns[i], actns[i+1], kernel_szs[i], stride=strides[i])\n",
    "        for i in range(len(strides))]\n",
    "    layers.append(nn.Sequential(AdaptiveConcatPool2d(1), Flatten()))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=5), HTML(value=''))), HTML(value='epoch  train loss  va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 00:27\n",
      "epoch  train loss  valid loss  accuracy\n",
      "0      0.079376    0.060103    0.979882  (00:05)\n",
      "1      0.045153    0.045692    0.983317  (00:05)\n",
      "2      0.034682    0.030597    0.987733  (00:05)\n",
      "3      0.030254    0.026142    0.989205  (00:05)\n",
      "4      0.027349    0.020678    0.992149  (00:05)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = simple_cnn((3,16,16,2))\n",
    "learner = Learner(data, model, metrics=[accuracy])\n",
    "learner.fit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3fb49aacccf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'show_doc' is not defined"
     ]
    }
   ],
   "source": [
    "show_doc(Lambda, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda allows us to define functions and use them as layers in our networks inside a [Sequential](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential) object. \n",
    "\n",
    "So, for example, say we want to apply a [log_softmax loss](https://pytorch.org/docs/stable/nn.html#torch.nn.functional.log_softmax) and we need to change the shape of our output batches to be able to use this loss. We can add a layer that applies the necessary change in shape by calling:\n",
    "\n",
    "`Lambda(lambda x: x.view(x.size(0),-1))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an example of how the shape of our output can change when we add this layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3,  16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    ")\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "for xb, yb in data.train_dl:\n",
    "    out = (model(*[xb]))\n",
    "    print(out.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3,  16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(lambda x: x.view(x.size(0),-1))\n",
    ")\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "for xb, yb in data.train_dl:\n",
    "    out = (model(*[xb]))\n",
    "    print(out.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=Flatten></a>`Flatten`\n",
       "> `Flatten`() -> `Tensor`\n",
       "\n",
       "\n",
       "Flattens `x` to a single dimension, often used at the end of a model <a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L21\">[source]</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function we build above is actually implemented in our library as [`Flatten`](/layers.html#flatten). We can see that it returns the same size when we run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3,  16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Flatten(),\n",
    ")\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "for xb, yb in data.train_dl:\n",
    "    out = (model(*[xb]))\n",
    "    print(out.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4eb6449c316d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPoolFlatten\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'show_doc' is not defined"
     ]
    }
   ],
   "source": [
    "show_doc(PoolFlatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine these two final layers ([AdaptiveAvgPool2d](https://pytorch.org/docs/stable/nn.html#torch.nn.AdaptiveAvgPool2d) and [`Flatten`](/layers.html#flatten)) by using [`Pool Flatten`](/layers.html#Pool Flatten)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3,  16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    PoolFlatten()\n",
    ")\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "for xb, yb in data.train_dl:\n",
    "    out = (model(*[xb]))\n",
    "    print(out.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=ResizeBatch></a>`ResizeBatch`\n",
       "> `ResizeBatch`(`size`:`int`) -> `Tensor`\n",
       "\n",
       "\n",
       "Layer that resizes x to `size`, good for connecting mismatched layers <a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L17\">[source]</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ResizeBatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another use we give to the Lambda function is to resize batches with [`ResizeBatch`](/layers.html#ResizeBatch) when we have a layer that expects a different input than what comes from the previous one. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., -1.],\n",
      "        [ 1., -1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1., -1.], [1., -1.]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., -1.,  1., -1.]])\n"
     ]
    }
   ],
   "source": [
    "out = ResizeBatch(4)\n",
    "print(out(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## <a id=StdUpsample></a>`class` `StdUpsample`\n",
       "> `StdUpsample`(`n_in`:`int`, `n_out`:`int`) :: [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n",
       "\n",
       "\n",
       "Increases the dimensionality of our data by applying a transposed convolution layer to the input and with batchnorm and a RELU activation <a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L75\">[source]</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(StdUpsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## <a id=CrossEntropyFlat></a>`class` `CrossEntropyFlat`\n",
       "> `CrossEntropyFlat`(`weight`=`None`, `size_average`=`None`, `ignore_index`=`-100`, `reduce`=`None`, `reduction`=`'elementwise_mean'`) :: [`CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss)\n",
       "<a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L93\">[source]</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CrossEntropyFlat, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "Same as [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss), but flattens input and target. Is used to calculate cross entropy on arrays (which Pytorch will not let us do with their [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss) function). An example of a use case is image segmentation models where the output in an image (or an array of pixels).\n",
    "\n",
    "The parameters are the same as [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss): `weight` to rescale each class, `size_average` whether we want to sum the losses across elements in a batch or we want to add them up, `ignore_index` what targets do we want to ignore, `reduce` on whether we want to return a loss per batch element and `reduction` specifies which type of reduction (if any) we want to apply to our input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-4bb3cd8bea20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDebugger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'show_doc' is not defined"
     ]
    }
   ],
   "source": [
    "show_doc(Debugger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "The debugger module allows us to peek inside a network while its training and see in detail what is going on. We can see inputs, ouputs and sizes at any point in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3,  16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    Debugger(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
    ")\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "learner = Learner(data, model, metrics=[accuracy])\n",
    "learner.fit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=bn_drop_lin></a>`bn_drop_lin`\n",
       "> `bn_drop_lin`(`n_in`:`int`, `n_out`:`int`, `bn`:`bool`=`True`, `p`:`float`=`0.0`, `actn`:`Optional`\\[[`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\\]=`None`)\n",
       "<a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L29\">[source]</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bn_drop_lin, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`Debugger`](/layers.html#Debugger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`bn_drop_lin`](/layers.html#bn_drop_lin) function returns a sequence of [batch normalization](https://arxiv.org/abs/1502.03167), [dropout](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf) and a linear layer. This custom layer is usually used at the end of a model. \n",
    "\n",
    "`n_in` represents the number of size of the input `n_out` the size of the output, `bn` whether we want batch norm or not, `p` is how much dropout and `actn` is an optional parameter to add an activation function at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=conv2d></a>`conv2d`\n",
       "> `conv2d`(`ni`:`int`, `nf`:`int`, `ks`:`int`=`3`, `stride`:`int`=`1`, `padding`:`int`=`None`, `bias`=`False`) -> [`Conv2d`](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d)\n",
       "\n",
       "\n",
       "Create `nn.Conv2d` layer: `ni` inputs, `nf` outputs, `ks` kernel size. `padding` defaults to `k//2` <a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L37\">[source]</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=conv2d_relu></a>`conv2d_relu`\n",
       "> `conv2d_relu`(`ni`:`int`, `nf`:`int`, `ks`:`int`=`3`, `stride`:`int`=`1`, `padding`:`int`=`None`, `bn`:`bool`=`False`) -> [`Sequential`](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential)\n",
       "\n",
       "\n",
       "Create a [`conv2d`](/layers.html#conv2d) layer with `nn.ReLU` activation and optional(`bn`) `nn.BatchNorm2d`: `ni` input, `nf` out filters, `ks` kernel, `stride`:stride, `padding`:padding, `bn`: batch normalization <a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L49\">[source]</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(conv2d_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=conv2d_trans></a>`conv2d_trans`\n",
       "> `conv2d_trans`(`ni`:`int`, `nf`:`int`, `ks`:`int`=`2`, `stride`:`int`=`2`, `padding`:`int`=`0`) -> [`ConvTranspose2d`](https://pytorch.org/docs/stable/nn.html#torch.nn.ConvTranspose2d)\n",
       "\n",
       "\n",
       "Create `nn.nn.ConvTranspose2d` layer: `ni` inputs, `nf` outputs, `ks` kernel size, `stride`: stride. `padding` defaults to 0 <a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L56\">[source]</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(conv2d_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=conv_layer></a>`conv_layer`\n",
       "> `conv_layer`(`ni`:`int`, `nf`:`int`, `ks`:`int`=`3`, `stride`:`int`=`1`) -> [`Sequential`](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential)\n",
       "<a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L42\">[source]</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(conv_layer, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`bn_drop_lin`](/layers.html#bn_drop_lin) function returns a sequence of [nn.Conv2D](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d), [BatchNorm2d](https://arxiv.org/abs/1502.03167) and a [leaky RELU](https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf) activation function.\n",
    "\n",
    "`n_in` represents the number of size of the input `n_out` the size of the output, `ks` kernel size, `stride` the stride with which we want to apply the convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=get_embedding></a>`get_embedding`\n",
       "> `get_embedding`(`ni`:`int`, `nf`:`int`) -> [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n",
       "<a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L115\">[source]</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(get_embedding, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates an [embedding layer](https://arxiv.org/abs/1711.09160) with input size `ni` and output size `nf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=simple_cnn></a>`simple_cnn`\n",
       "> `simple_cnn`(`actns`:`Collection`\\[`int`\\], `kernel_szs`:`Collection`\\[`int`\\]=`None`, `strides`:`Collection`\\[`int`\\]=`None`) -> [`Sequential`](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential)\n",
       "\n",
       "\n",
       "CNN with [`conv2d_relu`](/layers.html#conv2d_relu) layers defined by `actns`, `kernel_szs` and `strides` "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(simple_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=std_upsample_head></a>`std_upsample_head`\n",
       "> `std_upsample_head`(`c`, `nfs`:`Collection`\\[`int`\\]) -> [`Module`](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)\n",
       "<a href=\"https://github.com/fastai/fastai/blob/master/fastai/layers.py#L85\">[source]</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(std_upsample_head, doc_string=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a sequence of upsample layers with a RELU at the beggining and a [nn.ConvTranspose2d](https://pytorch.org/docs/stable/nn.html#torch.nn.ConvTranspose2d). \n",
    "\n",
    "`nfs` is a list with the input and output sizes of each upsample layer and `c` is the output size of the final 2D Transpose Convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "show_doc(trunc_normal_)"
   ]
  }
 ],
 "metadata": {
  "jekyll": {
   "summary": "`fastai.layers` provides essential functions to building and modifying `model` architectures",
   "title": "layers"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
