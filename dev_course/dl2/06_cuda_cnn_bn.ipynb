{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_05 import *\n",
    "torch.set_num_threads(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()\n",
    "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def normalize_to(train, valid):\n",
    "    m,s = train.mean(),train.std()\n",
    "    return normalize(train, m, s), normalize(valid, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_valid = normalize_to(x_train,x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh,bs = 50,512\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "data = DataBunch(*get_dls(train_ds, valid_ds, bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x): return self.func(x)\n",
    "\n",
    "def flatten(x):      return x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_resize(x): return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model(data):\n",
    "    return nn.Sequential(\n",
    "        Lambda(mnist_resize),\n",
    "        nn.Conv2d( 1, 8, 5, padding=2,stride=2), nn.ReLU(), #28\n",
    "        nn.Conv2d( 8,16, 3, padding=1,stride=2), nn.ReLU(), #14\n",
    "        nn.Conv2d(16,16, 3, padding=1,stride=2), nn.ReLU(), #7\n",
    "        nn.Conv2d(16,data.c,kernel_size=3,padding=1,stride=2),\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        Lambda(flatten)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_runner(model, lr=0.6, cbs=None, loss_func = F.cross_entropy):\n",
    "    opt = optim.SGD(model.parameters(), lr=lr)\n",
    "    learn = Learner(model, opt, loss_func, data)\n",
    "    return learn, Runner([AvgStatsCallback([accuracy])] + listify(cbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model(data)\n",
    "learn,run = get_runner(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [1.98849421875, tensor(0.3357)]\n",
      "valid: [0.65527548828125, tensor(0.7967)]\n",
      "CPU times: user 8min 18s, sys: 8min 6s, total: 16min 25s\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CudaCallback(Callback):\n",
    "    def begin_fit(self, run): run.model.cuda()\n",
    "    def begin_batch(self, run): run.xb,run.yb = run.xb.cuda(),run.yb.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model(data)\n",
    "learn,run = get_runner(model, cbs=CudaCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [2.18338203125, tensor(0.2367, device='cuda:0')]\n",
      "valid: [2.3074763671875, tensor(0.1064, device='cuda:0')]\n",
      "train: [2.2986975, tensor(0.1136, device='cuda:0')]\n",
      "valid: [2.2859005859375, tensor(0.1064, device='cuda:0')]\n",
      "train: [2.2883159375, tensor(0.1416, device='cuda:0')]\n",
      "valid: [2.30157578125, tensor(0.1064, device='cuda:0')]\n",
      "CPU times: user 4.16 s, sys: 932 ms, total: 5.09 s\n",
      "Wall time: 5.12 s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(ni, nf, ks=3, stride=2, act=True):\n",
    "    layers = [nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride)]\n",
    "    if act: layers.append(nn.ReLU())\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BatchTransformXCallback(Callback):\n",
    "    _order=2\n",
    "    def __init__(self, tfm): self.tfm = tfm\n",
    "    def begin_batch(self, run): run.xb = self.tfm(run.xb)\n",
    "\n",
    "def resize_tfm(*size):\n",
    "    def _inner(x): return x.view(*((-1,)+size))\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model can now work on any size input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_cnn_model(data, nfs):\n",
    "    nfs = [1] + nfs + [data.c]\n",
    "    layers = [\n",
    "        conv2d(nfs[i], nfs[i+1], 5 if i==1 else 3, act=i!=len(nfs)-1)\n",
    "        for i in range(len(nfs)-1)\n",
    "    ]\n",
    "    return nn.Sequential(\n",
    "        *layers,\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        Lambda(flatten)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs = [8,16,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model(data, nfs)\n",
    "learn,run = get_runner(model, cbs=[CudaCallback(), BatchTransformXCallback(resize_tfm(1,28,28))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [1.8743634375, tensor(0.3463, device='cuda:0')]\n",
      "valid: [0.64924033203125, tensor(0.8046, device='cuda:0')]\n",
      "train: [0.575943828125, tensor(0.8127, device='cuda:0')]\n",
      "valid: [0.432177783203125, tensor(0.8466, device='cuda:0')]\n",
      "train: [0.4277487890625, tensor(0.8507, device='cuda:0')]\n",
      "valid: [0.3820326904296875, tensor(0.8605, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batchnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_dims(x, dim):\n",
    "    numel = 1\n",
    "    for i in dim: numel *= x.shape[i]\n",
    "    s1 = x.sum(dim, keepdim=True)/numel\n",
    "    s2 = x.pow(2).sum(dim, keepdim=True)/numel\n",
    "    return s2 - s1**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, nf, mom=0.9, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # Our mom is (1-pytorch_mom), since pytorch is weird\n",
    "        self.mom,self.eps = mom,eps\n",
    "        self.mults = nn.Parameter(torch.ones (nf,1,1))\n",
    "        self.adds  = nn.Parameter(torch.zeros(nf,1,1))\n",
    "        self.register_buffer('vars',  torch.ones (1,nf,1,1))\n",
    "        self.register_buffer('means', torch.zeros(1,nf,1,1))\n",
    "\n",
    "    def update_stats(self, x):\n",
    "        m = x.mean((0,2,3), keepdim=True)\n",
    "        v = var_dims(x, (0,2,3)) # remove this once pytorch supports x.std(dim:tuple)\n",
    "        self.means.detach_()\n",
    "        self.vars.detach_()\n",
    "        self.means.lerp_(m, self.mom)\n",
    "        self.vars.lerp_ (v, self.mom)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.training: self.update_stats(x)\n",
    "        x = (x-self.means).div_((self.vars+self.eps).sqrt())\n",
    "        return x.mul_(self.mults).add_(self.adds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(ni, nf, ks=3, stride=2, act=True, bn=True):\n",
    "    # No bias needed if using bn\n",
    "    layers = [nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride, bias=not bn)]\n",
    "    if act: layers.append(nn.ReLU())\n",
    "    if bn: layers.append(BatchNorm(nf))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model(data, nfs)\n",
    "learn,run = get_runner(model, lr=0.4, cbs=[CudaCallback(), BatchTransformXCallback(resize_tfm(1,28,28))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.0682016064453125, tensor(0.9835, device='cuda:0')]\n",
      "valid: [0.07673294677734376, tensor(0.9793, device='cuda:0')]\n",
      "train: [0.0568701123046875, tensor(0.9865, device='cuda:0')]\n",
      "valid: [0.08219365234375, tensor(0.9775, device='cuda:0')]\n",
      "train: [0.0498054931640625, tensor(0.9881, device='cuda:0')]\n",
      "valid: [0.06638473510742188, tensor(0.9805, device='cuda:0')]\n",
      "train: [0.0449722265625, tensor(0.9890, device='cuda:0')]\n",
      "valid: [0.06726471557617188, tensor(0.9809, device='cuda:0')]\n",
      "train: [0.04034088623046875, tensor(0.9906, device='cuda:0')]\n",
      "valid: [0.05902564697265625, tensor(0.9831, device='cuda:0')]\n",
      "train: [0.0355039892578125, tensor(0.9913, device='cuda:0')]\n",
      "valid: [0.05814517211914062, tensor(0.9834, device='cuda:0')]\n",
      "CPU times: user 7.59 s, sys: 176 ms, total: 7.76 s\n",
      "Wall time: 7.79 s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(6, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.jit import ScriptModule, script_method, script\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@script\n",
    "def var1(x, dim:Tuple[int,int,int]):\n",
    "    numel = 1\n",
    "    for i in dim: numel = numel * x.shape[i]\n",
    "    s1 = x.sum(dim, keepdim=True)/numel\n",
    "    s2 = x.pow(2).sum(dim, keepdim=True)/numel\n",
    "    return s2 - s1**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(ScriptModule):\n",
    "    __constants__ = ['mom', 'eps']\n",
    "    def __init__(self, nf, mom=0.9, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.mom,self.eps = mom,eps\n",
    "        self.mults = nn.Parameter(torch.ones (nf,1,1))\n",
    "        self.adds  = nn.Parameter(torch.zeros(nf,1,1))\n",
    "        self.vars = torch.ones (1,nf,1,1).cuda()\n",
    "        self.means =torch.zeros(1,nf,1,1).cuda()\n",
    "#         self.register_buffer('vars',  torch.ones (1,nf,1,1))\n",
    "#         self.register_buffer('means', torch.zeros(1,nf,1,1))\n",
    "\n",
    "    @script_method\n",
    "    def update_stats(self, x):\n",
    "        m = x.mean((0,2,3), keepdim=True)\n",
    "        v = var1(x, (0,2,3)) # remove this once pytorch supports x.std(dim:tuple)\n",
    "        self.means.detach_()\n",
    "        self.vars.detach_()\n",
    "        self.means = self.means.mul(self.mom).add(1-self.mom, m)\n",
    "        self.vars  = self.vars.mul (self.mom).add(1-self.mom, v)\n",
    "#         self.means *= self.mom\n",
    "#         self.means += (1-self.mom)*m\n",
    "#         self.vars  *= self.mom\n",
    "#         self.vars  += (1-self.mom)*v\n",
    "\n",
    "    @script_method\n",
    "    def forward(self, x):\n",
    "        if self.training: self.update_stats(x)\n",
    "        x = (x-self.means).div((self.vars+self.eps).sqrt())\n",
    "        return x.mul(self.mults).add(self.adds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model(data, nfs)\n",
    "learn,run = get_runner(model, lr=0.4, cbs=[CudaCallback(), BatchTransformXCallback(resize_tfm(1,28,28))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.04733970703125, tensor(0.9881, device='cuda:0')]\n",
      "valid: [0.06652548217773438, tensor(0.9810, device='cuda:0')]\n",
      "train: [0.042660810546875, tensor(0.9893, device='cuda:0')]\n",
      "valid: [0.06790380249023438, tensor(0.9806, device='cuda:0')]\n",
      "train: [0.03964593994140625, tensor(0.9897, device='cuda:0')]\n",
      "valid: [0.05937213134765625, tensor(0.9828, device='cuda:0')]\n",
      "train: [0.0349819873046875, tensor(0.9918, device='cuda:0')]\n",
      "valid: [0.06547821655273438, tensor(0.9830, device='cuda:0')]\n",
      "train: [0.0333117529296875, tensor(0.9919, device='cuda:0')]\n",
      "valid: [0.06497180786132813, tensor(0.9812, device='cuda:0')]\n",
      "train: [0.03085428955078125, tensor(0.9923, device='cuda:0')]\n",
      "valid: [0.06038035888671875, tensor(0.9831, device='cuda:0')]\n",
      "CPU times: user 5.12 s, sys: 92 ms, total: 5.21 s\n",
      "Wall time: 5.24 s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(6, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0.dev20190313'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Builtin batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def conv2d(ni, nf, ks=3, stride=2, act=True, bn=True):\n",
    "    layers = [nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride, bias=not bn)]\n",
    "    if act: layers.append(nn.ReLU())\n",
    "    if bn: layers.append(nn.BatchNorm2d(nf))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model(data, nfs)\n",
    "learn,run = get_runner(model, lr=0.4, cbs=[CudaCallback(), BatchTransformXCallback(resize_tfm(1,28,28))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.049129072265625, tensor(0.9879, device='cuda:0')]\n",
      "valid: [0.08254159545898437, tensor(0.9761, device='cuda:0')]\n",
      "train: [0.0455973291015625, tensor(0.9886, device='cuda:0')]\n",
      "valid: [0.06360925903320312, tensor(0.9835, device='cuda:0')]\n",
      "train: [0.04050991943359375, tensor(0.9893, device='cuda:0')]\n",
      "valid: [0.06290653686523437, tensor(0.9829, device='cuda:0')]\n",
      "train: [0.03743682373046875, tensor(0.9906, device='cuda:0')]\n",
      "valid: [0.060035589599609376, tensor(0.9838, device='cuda:0')]\n",
      "train: [0.0341969921875, tensor(0.9914, device='cuda:0')]\n",
      "valid: [0.057718115234375, tensor(0.9842, device='cuda:0')]\n",
      "train: [0.031028759765625, tensor(0.9922, device='cuda:0')]\n",
      "valid: [0.06487869262695313, tensor(0.9823, device='cuda:0')]\n",
      "CPU times: user 5 s, sys: 68 ms, total: 5.07 s\n",
      "Wall time: 5.09 s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(6, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = combine_scheds([0.5, 0.5], [sched_lin(0.2, 0.8), sched_lin(0.8, 0.2)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model(data, nfs)\n",
    "learn,run = get_runner(model, lr=0.4, cbs=[Recorder(), CudaCallback(),\n",
    "    BatchTransformXCallback(resize_tfm(1,28,28)), ParamScheduler('lr', sched)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.682678984375, tensor(0.8528, device='cuda:0')]\n",
      "valid: [0.3456614501953125, tensor(0.8981, device='cuda:0')]\n",
      "train: [0.157797470703125, tensor(0.9604, device='cuda:0')]\n",
      "valid: [0.164066064453125, tensor(0.9537, device='cuda:0')]\n",
      "train: [0.08712751953125, tensor(0.9780, device='cuda:0')]\n",
      "valid: [0.07777939453125, tensor(0.9789, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = combine_scheds([0.5, 0.5], [sched_lin(0.2, 0.8), sched_lin(0.8, 0.01)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model(data, [8,16,32,64,32])\n",
    "learn,run = get_runner(model, lr=0.4, cbs=[Recorder(), CudaCallback(),\n",
    "    BatchTransformXCallback(resize_tfm(1,28,28)), ParamScheduler('lr', sched)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.498337421875, tensor(0.9000, device='cuda:0')]\n",
      "valid: [0.2021446044921875, tensor(0.9479, device='cuda:0')]\n",
      "train: [0.122512021484375, tensor(0.9708, device='cuda:0')]\n",
      "valid: [0.127957421875, tensor(0.9635, device='cuda:0')]\n",
      "train: [0.082052060546875, tensor(0.9785, device='cuda:0')]\n",
      "valid: [0.07273471069335938, tensor(0.9799, device='cuda:0')]\n",
      "train: [0.0615674462890625, tensor(0.9834, device='cuda:0')]\n",
      "valid: [0.09457974853515624, tensor(0.9709, device='cuda:0')]\n",
      "train: [0.042147236328125, tensor(0.9881, device='cuda:0')]\n",
      "valid: [0.07584328002929687, tensor(0.9770, device='cuda:0')]\n",
      "train: [0.025492666015625, tensor(0.9933, device='cuda:0')]\n",
      "valid: [0.04980409545898438, tensor(0.9852, device='cuda:0')]\n",
      "train: [0.0147454931640625, tensor(0.9970, device='cuda:0')]\n",
      "valid: [0.04962567443847656, tensor(0.9873, device='cuda:0')]\n",
      "train: [0.009472476806640625, tensor(0.9987, device='cuda:0')]\n",
      "valid: [0.04268844909667969, tensor(0.9887, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "run.fit(8, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 06_cuda_cnn_bn.ipynb to nb_06.py\r\n"
     ]
    }
   ],
   "source": [
    "!./notebook2script.py 06_cuda_cnn_bn.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
