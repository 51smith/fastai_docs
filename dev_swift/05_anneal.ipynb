{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(path: \"/home/ubuntu/fastai_docs/dev_swift/FastaiNotebooks\")\n",
      "\t\tFastaiNotebooks\n",
      "With SwiftPM flags: []\n",
      "Working in: /tmp/tmprbmf5ijf\n",
      "Fetching https://github.com/mxcl/Path.swift\n",
      "Fetching https://github.com/JustHTTP/Just\n",
      "Completed resolution in 2.01s\n",
      "Cloning https://github.com/mxcl/Path.swift\n",
      "Resolving https://github.com/mxcl/Path.swift at 0.16.2\n",
      "Cloning https://github.com/JustHTTP/Just\n",
      "Resolving https://github.com/JustHTTP/Just at 0.7.1\n",
      "Compile Swift Module 'Path' (9 sources)\n",
      "Compile Swift Module 'Just' (1 sources)\n",
      "Compile Swift Module 'FastaiNotebooks' (6 sources)\n",
      "Compile Swift Module 'jupyterInstalledPackages' (1 sources)\n",
      "Linking ./.build/x86_64-unknown-linux/debug/libjupyterInstalledPackages.so\n",
      "Initializing Swift...\n",
      "Loading library...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%install '.package(path: \"$cwd/FastaiNotebooks\")' FastaiNotebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FastaiNotebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "import Path\n",
    "import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let data = mnistDataBunch(flat: true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let (n,m) = (60000,784)\n",
    "let c = 10\n",
    "let nHid = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let opt = SGD<BasicModel, Float>(learningRate: 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func modelInit() -> BasicModel {return BasicModel(nIn: m, nHid: nHid, nOut: c)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func lossOutputWithGrad(\n",
    "    model: BasicModel,\n",
    "    in context: Context,\n",
    "    inputs: Tensor<Float>,\n",
    "    labels: Tensor<Int32>\n",
    ") -> (Tensor<Float>, BasicModel.Output, BasicModel.CotangentVector) {\n",
    "    var outputs: BasicModel.Output? = nil\n",
    "    let (loss, grads) = model.valueWithGradient { model -> Tensor<Float> in\n",
    "        let predictions = model.applied(to: inputs, in: context)\n",
    "        outputs = predictions\n",
    "        return softmaxCrossEntropy(logits: predictions, labels: labels)\n",
    "    }\n",
    "    return (loss, outputs!, grads)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let learner = Learner(data: data, lossOutputWithGradient: lossOutputWithGrad, optimizer: opt, initializingWith: modelInit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.delegates = [Learner.TrainEvalDelegate(), Learner.AvgMetric(metrics: [accuracy])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning epoch 0\n",
      "[0.4615099, 0.8826]\n",
      "Beginning epoch 1\n",
      "[0.3536407, 0.903]\n"
     ]
    }
   ],
   "source": [
    "learner.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Callbacks\n",
    "\n",
    "The code below adds callbacks and defines a new training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// CallbackResult allows callbacks to control the training loop.\n",
    "public enum CallbackResult {\n",
    "    /// Proceed with the training step.\n",
    "    case proceed\n",
    "    /// Skip the rest of the training step, and move immediately to the next step.\n",
    "    case skip\n",
    "    /// Stop training.\n",
    "    case stop\n",
    "}\n",
    "\n",
    "\n",
    "open class TrainingCallbacks<M, O: Optimizer, S> \n",
    "    where O.Model == M, O.Scalar == S,\n",
    "          M.Input == Tensor<S>, M.Output == Tensor<S> {\n",
    "              \n",
    "    open func beforeTrain(model: inout M, optimizer: inout O) -> CallbackResult {\n",
    "        return .proceed\n",
    "    }\n",
    "    \n",
    "    // TODO: Figure out what to pass here!\n",
    "    open func beforeBatch() -> CallbackResult {\n",
    "        return .proceed\n",
    "    }\n",
    "    \n",
    "    open func afterBatch(loss: inout Tensor<S>) -> CallbackResult {\n",
    "        return .proceed\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recorder<M, O: Optimizer, S>: TrainingCallbacks<M, O, S>\n",
    "    where O.Model == M, O.Scalar == S,\n",
    "          M.Input == Tensor<S>, M.Output == Tensor<S> {\n",
    "    private var optimizer: O? = nil\n",
    "    private var losses: [S] = []\n",
    "    private var lrs: [O.Scalar] = []\n",
    "    override func beforeTrain(model: inout M, optimizer: inout O) -> CallbackResult {\n",
    "        self.optimizer = optimizer\n",
    "        return .proceed\n",
    "    }\n",
    "    \n",
    "    override func afterBatch(loss: inout Tensor<S>) -> CallbackResult {\n",
    "        lrs.append(optimizer!.learningRate)\n",
    "        losses.append(loss.scalarized())\n",
    "        return .proceed\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// Simple SGD optimizer with a modifiable learning rate.\n",
    "public class SettableSGD<Model: Layer>: Optimizer\n",
    "    where Model.AllDifferentiableVariables == Model.CotangentVector {\n",
    "    /// The learning rate.\n",
    "    public var learningRate: Float {\n",
    "        willSet(newLearningRate) {\n",
    "            precondition(newLearningRate >= 0, \"Learning rate must be non-negative\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "    public init(learningRate: Float = 0.01) {\n",
    "        precondition(learningRate >= 0, \"Learning rate must be non-negative\")\n",
    "        self.learningRate = learningRate\n",
    "    }\n",
    "\n",
    "    public func update(_ model: inout Model.AllDifferentiableVariables,\n",
    "                       along direction: Model.CotangentVector) {\n",
    "        for kp in model.recursivelyAllWritableKeyPaths(to: Tensor<Scalar>.self) {\n",
    "            model[keyPath: kp] += learningRate * direction[keyPath: kp]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let foo = SettableSGD<Dense<Float>>()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.learningRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.learningRate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo.learningRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// A non-generalized learning rate scheduler\n",
    "class LearningRateScheduler<M, O: SettableSGD<M>>: TrainingCallbacks<M, O, Float>\n",
    "    where O.Model == M,\n",
    "          M.Input == Tensor<Float>, M.Output == Tensor<Float> {\n",
    "    \n",
    "    // A learning rate schedule from step to float.\n",
    "    typealias ScheduleFunc = (Int) -> Float\n",
    "\n",
    "    private var optimizer: O?\n",
    "    private let scheduler: ScheduleFunc\n",
    "    private var step = 0\n",
    "    \n",
    "    init(scheduler: @escaping ScheduleFunc) {\n",
    "        self.scheduler = scheduler\n",
    "    }\n",
    "\n",
    "    override func beforeTrain(model: inout M, optimizer: inout O) -> CallbackResult {\n",
    "        self.optimizer = optimizer\n",
    "        return .proceed\n",
    "    }\n",
    "              \n",
    "    override func beforeBatch() -> CallbackResult {\n",
    "        step += 1\n",
    "        self.optimizer!.learningRate = scheduler(step)\n",
    "        return .proceed\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialCallbacks< M, O: Optimizer, S>: TrainingCallbacks<M, O, S>\n",
    "    where O.Model == M, O.Scalar == S,\n",
    "          M.Input == Tensor<S>, M.Output == Tensor<S> {\n",
    "    \n",
    "    private let callbacks: [TrainingCallbacks<M, O, S>]\n",
    "\n",
    "    init(_ callbacks: [TrainingCallbacks<M, O, S>]) {\n",
    "        self.callbacks = callbacks\n",
    "    }\n",
    "    convenience init(_ callbacks: TrainingCallbacks<M, O, S>...) {\n",
    "        self.init(callbacks)\n",
    "    }\n",
    "              \n",
    "    override func beforeTrain(model: inout M, optimizer: inout O) -> CallbackResult {\n",
    "        for cb in callbacks {\n",
    "            let cbResult = cb.beforeTrain(model: &model, optimizer: &optimizer)\n",
    "            switch cbResult {\n",
    "                case .stop, .skip: return cbResult\n",
    "                case .proceed: break\n",
    "            }\n",
    "        }\n",
    "        return .proceed\n",
    "    }\n",
    "    \n",
    "    // TODO: Figure out what to pass here!\n",
    "    override func beforeBatch() -> CallbackResult {\n",
    "        for cb in callbacks {\n",
    "            let cbResult = cb.beforeBatch()\n",
    "            switch cbResult {\n",
    "                case .stop, .skip: return cbResult\n",
    "                case .proceed: break\n",
    "            }\n",
    "        }\n",
    "        return .proceed\n",
    "    }\n",
    "    \n",
    "    override func afterBatch(loss: inout Tensor<S>) -> CallbackResult {\n",
    "        for cb in callbacks {\n",
    "            let cbResult = cb.afterBatch(loss: &loss)\n",
    "            switch cbResult {\n",
    "                case .stop, .skip: return cbResult\n",
    "                case .proceed: break\n",
    "            }\n",
    "        }\n",
    "        return .proceed\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// A training loop, now improved with callbacks!\n",
    "public func trainWithCallbacks<M, O: Optimizer, S>(\n",
    "    _ model: inout M,\n",
    "    at variablesKeyPath: WritableKeyPath<M, M.AllDifferentiableVariables>,\n",
    "    on dataset: Dataset<Example<S, S>>,\n",
    "    using optimizer: inout O,\n",
    "    loss: @escaping @differentiable (Tensor<S>, Tensor<S>) -> Tensor<S>,\n",
    "    callbacks: TrainingCallbacks<M, O, S>\n",
    ") where O.Model == M, O.Scalar == S,\n",
    "        M.Input == Tensor<S>, M.Output == Tensor<S>\n",
    "{\n",
    "    let context = Context(learningPhase: .training)\n",
    "    callbacks.beforeTrain(model: &model, optimizer: &optimizer)\n",
    "    for batch in dataset {\n",
    "        callbacks.beforeBatch()  // TODO: pass in batch!\n",
    "        let (x, y) = (batch.data, batch.labels)\n",
    "        var (loss, (𝛁model, _)) = model.valueWithGradient(at: y) { (model, y) -> Tensor<S> in\n",
    "            let preds = model.applied(to: x, in: context)\n",
    "            return loss(preds, y)\n",
    "        }\n",
    "        callbacks.afterBatch(loss: &loss)\n",
    "        print(loss)\n",
    "        optimizer.update(&model[keyPath: variablesKeyPath], along: 𝛁model)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
